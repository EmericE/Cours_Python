{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import used packages\n",
    "import numpy as np\n",
    "import pickle # save and load binary files (data, model)\n",
    "\n",
    "# Set jupyter display in full screen\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to import and export data from cPickle format\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "def save_obj(obj, name):\n",
    "    with open('export/' + name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les données dans des array numpy (2 fichiers: features et labels). Utiliser les fonctions de pickle définies plus haut. \n",
    "# Regarder les dimensions des données.\n",
    "featuresFile = 'data/Sigma_features.pkl'\n",
    "labelFile = 'data/Sigma_labels.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter le biai dans les variables (features). Équivaut à rajouter une variables (une colonne)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Définir le modèle (régression linéaire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer le vecteur de paramètres (attention aux dimensions). Pour tester, il faut donc l'initialiser aléatoirement. Attention aux dimensions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition du modèle (hypothèse) qui permet de combiner les variables et les paramètres. On utilise une fonction python!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Descente de gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de coût. On utilisera une fonction python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dérivée de la fonction de coût == gradients. Attention aux dimensions lors de la somme! (poser le calcul matriciel sur papier pour être sûr). On utilisera une fonction python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent: mise à jour des paramètres. Il faudra définir un alpha. On utilisera une fonction qui prendra l'objet paramètres en arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction pour tester l'évolution de la fonction de coût: vrai = continuer la descente de gradient\n",
    "#   Si la fonction de coût à diminué de moins de epsilon % entre deux étapes: on arrête la descente de gradients (epsilon << 1, à définir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) On combine le tout dans une boucle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation. Créer une fonction d'initialisation qui retourne les objets dont on aura besoin pour notre descente de gradients (paramètres, predictions, alpha, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# On utilise une boucle while pour implémenter notre descente de gradient en utilisant toute les fonctions (tout les blocs de codes) que nous avons définis plus tôt.\n",
    "# Penser à ajouter un affichage de monitoring de la descente de gradient!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) (Bonus) Régularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En cas d'overfitting (problème de variance): le modèle ne généralise pas bien à de nouvelle valeurs\n",
    "# on peut utiliser des méthodes de régularisation (ici nous allons coder la régularisation L2: voir wikipedia ou autres)\n",
    "# Il faut donc adapter nos précédentes fonctions: fonction de coût, calcul du gradients ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
